# basic_ai_agent


## LangGraph ReAct Agent with Gemini + Tavily

This project demonstrates how to build a **ReAct agent** using [LangGraph](https://github.com/langchain-ai/langgraph), powered by **Google Gemini (via LangChain)** and enhanced with the **Tavily Search tool** for web retrieval.  
It includes optional **checkpointing/memory** support (in-memory or SQLite) so your agent can remember conversation history.

---

### ğŸš€ Features

- **Gemini 2.5 Flash** via LangChainâ€™s `init_chat_model`
- **Tavily Search integration** for real-time web results
- **Direct tool-calling** (`model.bind_tools`)
- **ReAct agent** orchestration with `create_react_agent`
- **Streaming support** for token-level updates
- **Checkpointing** with either:
  - `MemorySaver` (ephemeral, in-memory)
  - `SqliteSaver` (persistent, across runs)
- **LangSmith optional tracing** for debugging & monitoring

---

### ğŸ“¦ Installation

```bash
pip install -r requirements.txt
```

### ğŸ” Configure Environment

Copy the example env and fill your keys:

```bash
cp .env.example .env
```

### ğŸƒ Running

Always run with -m from the repo root so Python treats app/ as a package.

A) Direct tool-calling demo

```bash
python -m app.runners.demo_direct
```

Youâ€™ll see:

    * A normal â€œHi!â€ response
    * A tool-bound call that uses Tavily for: â€œSearch for weather in Bangaloreâ€
    (Reminder: Tavily is a search tool, not a live weather API.)

B) ReAct agent with memory/checkpointing

```bash
python -m app.runners.demo_agent
```

This uses LangGraph create_react_agent and streams two turns:

    1. â€œHi, Iâ€™m Maheshkrishnaâ€
    2. â€œWhatâ€™s my name?â€ 

It sets a consistent thread_id so the second turn can use prior state.


### ğŸ§° Dev Tooling (Ruff)

```aiignore
# Lint
ruff check app/
ruff check app/ --fix

# Format
ruff format app/
```

Rules & settings live in pyproject.toml.

